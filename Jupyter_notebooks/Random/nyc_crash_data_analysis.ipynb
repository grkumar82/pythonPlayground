{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd2d50d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset source: https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95\n",
    "# questions\n",
    "# which borough had most crashes by year?\n",
    "# Group incidents at the top of the hour and find out top 3 times of the day that saw the most crashes?\n",
    "# If a incident had a fatality, what was the average fatality?\n",
    "# what were top 3 zip codes where most incidents happened by each of NYC borough by year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776cf8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6fed608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/01 20:45:19 WARN Utils: Your hostname, Ravis-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.6.23 instead (on interface en0)\n",
      "23/06/01 20:45:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/01 20:45:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# create spark session\n",
    "spark = SparkSession.builder.appName(\"analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7213c66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read dataset\n",
    "raw_df = spark.read.csv(\"crashes.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2675c5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1996742"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of rows in the dataframe\n",
    "raw_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "398ea2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CRASH DATE: string (nullable = true)\n",
      " |-- CRASH TIME: string (nullable = true)\n",
      " |-- BOROUGH: string (nullable = true)\n",
      " |-- ZIP CODE: string (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- ON STREET NAME: string (nullable = true)\n",
      " |-- CROSS STREET NAME: string (nullable = true)\n",
      " |-- OFF STREET NAME: string (nullable = true)\n",
      " |-- NUMBER OF PERSONS INJURED: string (nullable = true)\n",
      " |-- NUMBER OF PERSONS KILLED: integer (nullable = true)\n",
      " |-- NUMBER OF PEDESTRIANS INJURED: integer (nullable = true)\n",
      " |-- NUMBER OF PEDESTRIANS KILLED: integer (nullable = true)\n",
      " |-- NUMBER OF CYCLIST INJURED: integer (nullable = true)\n",
      " |-- NUMBER OF CYCLIST KILLED: string (nullable = true)\n",
      " |-- NUMBER OF MOTORIST INJURED: string (nullable = true)\n",
      " |-- NUMBER OF MOTORIST KILLED: integer (nullable = true)\n",
      " |-- CONTRIBUTING FACTOR VEHICLE 1: string (nullable = true)\n",
      " |-- CONTRIBUTING FACTOR VEHICLE 2: string (nullable = true)\n",
      " |-- CONTRIBUTING FACTOR VEHICLE 3: string (nullable = true)\n",
      " |-- CONTRIBUTING FACTOR VEHICLE 4: string (nullable = true)\n",
      " |-- CONTRIBUTING FACTOR VEHICLE 5: string (nullable = true)\n",
      " |-- COLLISION_ID: integer (nullable = true)\n",
      " |-- VEHICLE TYPE CODE 1: string (nullable = true)\n",
      " |-- VEHICLE TYPE CODE 2: string (nullable = true)\n",
      " |-- VEHICLE TYPE CODE 3: string (nullable = true)\n",
      " |-- VEHICLE TYPE CODE 4: string (nullable = true)\n",
      " |-- VEHICLE TYPE CODE 5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c972af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "# count of rows by collision_id should be equal to total count of rows\n",
    "row_count_df = raw_df.select(countDistinct(col(\"COLLISION_ID\")).alias(\"row_cnt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e901150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                        (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|row_cnt|\n",
      "+-------+\n",
      "|1996740|\n",
      "+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "row_count_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78db1278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------------+\n",
      "|crash_year|  BOROUGH|COLLISION_ID|\n",
      "+----------+---------+------------+\n",
      "|      2021|     null|     4455765|\n",
      "|      2022|     null|     4513547|\n",
      "|      2022|     null|     4541903|\n",
      "|      2021| BROOKLYN|     4456314|\n",
      "|      2021| BROOKLYN|     4486609|\n",
      "|      2021|     null|     4407458|\n",
      "|      2021|     null|     4486555|\n",
      "|      2021|    BRONX|     4486660|\n",
      "|      2021| BROOKLYN|     4487074|\n",
      "|      2021|MANHATTAN|     4486519|\n",
      "+----------+---------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# questions\n",
    "# output the borough that had most creashes for every year?\n",
    "borough_year_raw = raw_df.withColumn(\"crash_year\", split(\"CRASH DATE\", '/')[2]).select(\"crash_year\", \"BOROUGH\", \"COLLISION_ID\")\n",
    "borough_year_raw.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3533db85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/01 20:45:39 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 14:>                                                       (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|crash_year| BOROUGH|\n",
      "+----------+--------+\n",
      "|      2012|BROOKLYN|\n",
      "|      2013|BROOKLYN|\n",
      "|      2014|BROOKLYN|\n",
      "|      2015|BROOKLYN|\n",
      "|      2016|BROOKLYN|\n",
      "|      2017|BROOKLYN|\n",
      "|      2018|BROOKLYN|\n",
      "|      2019|BROOKLYN|\n",
      "|      2020|BROOKLYN|\n",
      "|      2021|BROOKLYN|\n",
      "|      2022|BROOKLYN|\n",
      "|      2023|BROOKLYN|\n",
      "+----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# remove all rows of data where the borough is null\n",
    "cleaned_borough_data = borough_year_raw.dropna(subset=[\"BOROUGH\", \"crash_year\"])\n",
    "# which borough had most crashes by year?\n",
    "cleaned_borough_data.createOrReplaceTempView(\"table\")\n",
    "top_years_sql = spark.sql(\n",
    "f\"\"\"\n",
    "WITH CTE AS(\n",
    "SELECT\n",
    "    crash_year,\n",
    "    BOROUGH,\n",
    "    RANK() OVER(PARTITION BY crash_year ORDER BY COUNT(DISTINCT COLLISION_ID) DESC) AS rnk\n",
    "    FROM table\n",
    "    GROUP BY 1,2\n",
    "    )\n",
    "SELECT \n",
    "crash_year,\n",
    "BOROUGH\n",
    "FROM CTE\n",
    "WHERE rnk = 1\n",
    "ORDER BY 1\n",
    "\"\"\")\n",
    "top_years_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46825fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 97:>                                                       (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------+---+\n",
      "|crash_year| BOROUGH|collision_cnt|rnk|\n",
      "+----------+--------+-------------+---+\n",
      "|      2012|BROOKLYN|        23305|  1|\n",
      "|      2013|BROOKLYN|        47021|  1|\n",
      "|      2014|BROOKLYN|        47758|  1|\n",
      "|      2015|BROOKLYN|        50847|  1|\n",
      "|      2016|BROOKLYN|        47464|  1|\n",
      "|      2017|BROOKLYN|        44915|  1|\n",
      "|      2018|BROOKLYN|        47313|  1|\n",
      "|      2019|BROOKLYN|        44479|  1|\n",
      "|      2020|BROOKLYN|        25472|  1|\n",
      "|      2021|BROOKLYN|        25171|  1|\n",
      "|      2022|BROOKLYN|        23357|  1|\n",
      "|      2023|BROOKLYN|         8803|  1|\n",
      "+----------+--------+-------------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# in pyspark\n",
    "cte = cleaned_borough_data.groupBy(\"crash_year\",\"BOROUGH\")\\\n",
    ".agg(countDistinct(\"COLLISION_ID\").alias(\"collision_cnt\"))\n",
    "# cte.show()\n",
    "window_spec = Window.partitionBy(\"crash_year\").orderBy(col(\"collision_cnt\").desc())\n",
    "ranked_cte = cte.withColumn(\"rnk\", rank().over(window_spec))\n",
    "# select rows with rnk = 1\n",
    "result = ranked_cte.filter(col(\"rnk\") == 1).orderBy(\"crash_year\")\n",
    "result.show()\n",
    "# .select(\"crash_year\",\"BOROUGH\", countDistinct(\"COLLISION_ID\").alias(\"collision_cnt\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b21faf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:>                                                       (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+\n",
      "|hour|collision_cnt|\n",
      "+----+-------------+\n",
      "|  16|       144542|\n",
      "|  17|       141298|\n",
      "|  14|       133834|\n",
      "+----+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# What are the top 3 times of the day saw the most crashes?\n",
    "# round the time to top of hour i.e. 2:39 -> 2 or 21:10 -> 21\n",
    "df_hour = raw_df.withColumn(\"hour\", expr(\"hour(to_timestamp(`CRASH TIME`, 'H:mm'))\"))\\\n",
    ".select(\"COLLISION_ID\", col(\"CRASH TIME\"), \"hour\")\n",
    "df_hour_summarized = df_hour.groupBy(\"hour\")\\\n",
    ".agg(countDistinct(\"COLLISION_ID\").alias(\"collision_cnt\"))\\\n",
    ".orderBy(\"collision_cnt\", ascending=False)\\\n",
    ".limit(3)\n",
    "\n",
    "df_hour_summarized.show()\n",
    "# df.select(\"hour\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0058157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:>                                                       (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|avg_killed|\n",
      "+----------+\n",
      "|      1.36|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# If a incident had a fatality, what was the average fatality?\n",
    "curated_fatal_df = raw_df.select(col(\"NUMBER OF PERSONS INJURED\").alias(\"person_killed\")\\\n",
    ",col(\"NUMBER OF CYCLIST KILLED\").alias(\"cyclist_killed\")\n",
    ",col(\"NUMBER OF PEDESTRIANS KILLED\").alias(\"pedestration_killed\")\n",
    ",col(\"NUMBER OF MOTORIST KILLED\").alias(\"motorist_killed\")\n",
    ",\"COLLISION_ID\")\n",
    "curated_fatal_df.createOrReplaceTempView(\"table\")\n",
    "fatal_query = spark.sql(\n",
    "f\"\"\"\n",
    "WITH CTE AS \n",
    "(\n",
    "SELECT \n",
    "DISTINCT COLLISION_ID,\n",
    "total_killed\n",
    "FROM\n",
    "(\n",
    "SELECT \n",
    "COLLISION_ID,\n",
    "(person_killed + cyclist_killed + pedestration_killed + motorist_killed) AS total_killed\n",
    "FROM table\n",
    ") temp\n",
    "WHERE total_killed > 0\n",
    ")\n",
    "SELECT\n",
    "ROUND(AVG(total_killed), 2) AS avg_killed\n",
    "FROM CTE\n",
    "\"\"\"\n",
    ")\n",
    "fatal_query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9bd5d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 108:================>                                       (3 + 7) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|avg_killed|\n",
      "+----------+\n",
      "|      1.36|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "inner_df = curated_fatal_df.withColumn(\"total_killed\", \\\n",
    "            expr(\"person_killed + cyclist_killed + pedestration_killed + motorist_killed\"))\\\n",
    ".distinct()\\\n",
    ".where(col(\"total_killed\") > 0)\n",
    "\n",
    "result = inner_df.select(expr(\"ROUND(AVG(total_killed), 2)\").alias(\"avg_killed\"))\n",
    "result.show()\n",
    "# avg_fatalities_df = inner_df.withColumn(\"avg_killed\", round(avg(col(\"total_killed\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8adaad73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 114:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+-------------+\n",
      "|crash_year|      BOROUGH|zip_code|collision_cnt|\n",
      "+----------+-------------+--------+-------------+\n",
      "|      2012|        BRONX|   10458|          547|\n",
      "|      2012|        BRONX|   10466|          566|\n",
      "|      2012|        BRONX|   10467|          693|\n",
      "|      2012|     BROOKLYN|   11201|         1034|\n",
      "|      2012|     BROOKLYN|   11203|          946|\n",
      "|      2012|     BROOKLYN|   11207|         1345|\n",
      "|      2012|    MANHATTAN|   10019|         1125|\n",
      "|      2012|    MANHATTAN|   10022|         1224|\n",
      "|      2012|    MANHATTAN|   10036|         1122|\n",
      "|      2012|       QUEENS|   11101|         1054|\n",
      "|      2012|       QUEENS|   11385|          857|\n",
      "|      2012|       QUEENS|   11434|          738|\n",
      "|      2012|STATEN ISLAND|   10306|          706|\n",
      "|      2012|STATEN ISLAND|   10312|          491|\n",
      "|      2012|STATEN ISLAND|   10314|         1076|\n",
      "|      2013|        BRONX|   10458|         1158|\n",
      "|      2013|        BRONX|   10467|         1567|\n",
      "|      2013|        BRONX|   10468|         1115|\n",
      "|      2013|     BROOKLYN|   11201|         2034|\n",
      "|      2013|     BROOKLYN|   11203|         1938|\n",
      "+----------+-------------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# what were top 3 zip codes where most incidents happened by each of boroughs by year?\n",
    "borough_year_raw = raw_df.withColumn(\"crash_year\", split(\"CRASH DATE\", '/')[2])\\\n",
    ".select(\"crash_year\", col(\"ZIP CODE\").alias(\"zip_code\"), \"BOROUGH\", \"COLLISION_ID\")\n",
    "# drop Null\n",
    "non_null_borough_year_raw = borough_year_raw.dropna(subset=['BOROUGH', 'crash_year'])\n",
    "non_null_borough_year_raw.createOrReplaceTempView(\"table\")\n",
    "top_3 = spark.sql(\n",
    "f\"\"\"\n",
    "WITH CTE AS\n",
    "(\n",
    "SELECT\n",
    "crash_year,\n",
    "BOROUGH,\n",
    "zip_code,\n",
    "collision_cnt,\n",
    "DENSE_RANK() OVER (PARTITION BY crash_year, BOROUGH ORDER BY collision_cnt DESC) AS rnk\n",
    "FROM \n",
    "(\n",
    "SELECT \n",
    "crash_year,\n",
    "BOROUGH,\n",
    "zip_code,\n",
    "COUNT(DISTINCT COLLISION_ID) AS collision_cnt\n",
    "FROM table\n",
    "GROUP BY 1,2,3\n",
    ") temp\n",
    ")\n",
    "\n",
    "SELECT \n",
    "crash_year,\n",
    "BOROUGH,\n",
    "zip_code,\n",
    "collision_cnt\n",
    "FROM CTE\n",
    "WHERE rnk < 4\n",
    "ORDER BY 1,2,3,4 DESC\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "top_3.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e71889a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 124:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+-------------+---+\n",
      "|crash_year|      BOROUGH|zip_code|collision_cnt|rnk|\n",
      "+----------+-------------+--------+-------------+---+\n",
      "|      2012|        BRONX|   10458|          547|  3|\n",
      "|      2012|        BRONX|   10466|          566|  2|\n",
      "|      2012|        BRONX|   10467|          693|  1|\n",
      "|      2012|     BROOKLYN|   11201|         1034|  2|\n",
      "|      2012|     BROOKLYN|   11203|          946|  3|\n",
      "|      2012|     BROOKLYN|   11207|         1345|  1|\n",
      "|      2012|    MANHATTAN|   10019|         1125|  2|\n",
      "|      2012|    MANHATTAN|   10022|         1224|  1|\n",
      "|      2012|    MANHATTAN|   10036|         1122|  3|\n",
      "|      2012|       QUEENS|   11101|         1054|  1|\n",
      "|      2012|       QUEENS|   11385|          857|  2|\n",
      "|      2012|       QUEENS|   11434|          738|  3|\n",
      "|      2012|STATEN ISLAND|   10306|          706|  2|\n",
      "|      2012|STATEN ISLAND|   10312|          491|  3|\n",
      "|      2012|STATEN ISLAND|   10314|         1076|  1|\n",
      "|      2013|        BRONX|   10458|         1158|  2|\n",
      "|      2013|        BRONX|   10467|         1567|  1|\n",
      "|      2013|        BRONX|   10468|         1115|  3|\n",
      "|      2013|     BROOKLYN|   11201|         2034|  2|\n",
      "|      2013|     BROOKLYN|   11203|         1938|  3|\n",
      "+----------+-------------+--------+-------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "non_null_borough_year_cte1 = non_null_borough_year_raw.groupBy(\"crash_year\",\\\n",
    "\"BOROUGH\",\"zip_code\")\\\n",
    ".agg(countDistinct(\"COLLISION_ID\").alias(\"collision_cnt\"))\n",
    "\n",
    "window_spec = Window.partitionBy(\"crash_year\", \"BOROUGH\").orderBy(col(\"collision_cnt\").desc())\n",
    "non_null_borough_year_cte2 = non_null_borough_year_cte1.withColumn(\"rnk\", \\\n",
    " dense_rank().over(window_spec))\n",
    "\n",
    "result_df = non_null_borough_year_cte2.filter(col(\"rnk\") < 4)\\\n",
    ".orderBy(\"crash_year\", \"BOROUGH\", \"zip_code\", \"collision_cnt\")\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0440c84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
